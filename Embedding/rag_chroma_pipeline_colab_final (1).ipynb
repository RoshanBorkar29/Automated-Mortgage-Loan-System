{"nbformat":4,"nbformat_minor":5,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python","version":"3.x"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0FQnJJC1S-oi"},"source":["# RAG pipeline with Chroma, Sentence-Transformers, and FLAN-T5 (Colab-ready)\n","\n","This Colab notebook implements:\n","- OCR-aware PDF extraction (handles flattened PDFs) using `pdfplumber` + `pytesseract`.\n","- Text extraction from DOCX and images.\n","- Chunking and per-document JSON export.\n","- Embeddings with `sentence-transformers` (recommended: `all-mpnet-base-v2`).\n","- Vector storage in Chroma (local persistent folder).\n","- Retrieval (query → embedding → top-K).\n","- RAG answer synthesis using `google/flan-t5-base`.\n","- Optional exact-span extraction using a QA model.\n","\n","**How to use**\n","1. Open this notebook in Google Colab.\n","2. (Optional) Change runtime to GPU for faster generation: Runtime → Change runtime type → GPU.\n","3. Run cells sequentially. Upload files when prompted (or mount Google Drive and modify paths).\n","4. Use the `rag_answer` function to ask questions.\n","\n"],"id":"0FQnJJC1S-oi"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-OiwxioCS-ok","executionInfo":{"status":"ok","timestamp":1764728193450,"user_tz":-330,"elapsed":58219,"user":{"displayName":"Hariom Ramkrishna","userId":"08131443419838177211"}},"outputId":"3787e0a5-e7c9-4016-9c0a-8a3cc5a7ddbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-adk 1.19.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n","google-adk 1.19.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n","opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n","opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n","opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Selecting previously unselected package libarchive-dev:amd64.\n","(Reading database ... 121713 files and directories currently installed.)\n","Preparing to unpack .../libarchive-dev_3.6.0-1ubuntu1.5_amd64.deb ...\n","Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.5) ...\n","Selecting previously unselected package libleptonica-dev.\n","Preparing to unpack .../libleptonica-dev_1.82.0-3build1_amd64.deb ...\n","Unpacking libleptonica-dev (1.82.0-3build1) ...\n","Selecting previously unselected package libtesseract-dev:amd64.\n","Preparing to unpack .../libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n","Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n","Selecting previously unselected package poppler-utils.\n","Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.12_amd64.deb ...\n","Unpacking poppler-utils (22.02.0-2ubuntu0.12) ...\n","Setting up libleptonica-dev (1.82.0-3build1) ...\n","Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.5) ...\n","Setting up poppler-utils (22.02.0-2ubuntu0.12) ...\n","Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n"]}],"execution_count":1,"source":["# Install required packages (Colab)\n","!pip install -q sentence-transformers chromadb pdfplumber python-docx pytesseract pillow transformers accelerate sentencepiece\n","# install tesseract binary (Colab / Debian) and poppler-utils for PDF rasterization\n","!apt-get update -qq && apt-get install -y -qq tesseract-ocr libtesseract-dev poppler-utils\n"],"id":"-OiwxioCS-ok"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a5rxZ48MS-ok","executionInfo":{"status":"ok","timestamp":1764728269385,"user_tz":-330,"elapsed":41808,"user":{"displayName":"Hariom Ramkrishna","userId":"08131443419838177211"}},"outputId":"0b23036d-2bc8-469f-e4ce-6c747531747f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Embedding model: all-mpnet-base-v2\n","Generation model: google/flan-t5-base\n","DB_DIR: /content/chroma_db\n"]}],"execution_count":2,"source":["# Imports, paths, and settings\n","import os, json, uuid\n","from pathlib import Path\n","from tqdm import tqdm\n","\n","# Text extraction libs\n","import pdfplumber, docx\n","from PIL import Image, ImageFilter, ImageOps\n","import pytesseract\n","\n","# Embeddings\n","from sentence_transformers import SentenceTransformer\n","\n","# Chroma\n","import chromadb\n","from chromadb.config import Settings\n","\n","# Generation & QA\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n","import torch\n","\n","# Folders\n","DB_DIR = \"/content/chroma_db\"\n","JSON_OUTPUT_DIR = \"/content/doc_jsons\"\n","os.makedirs(DB_DIR, exist_ok=True)\n","os.makedirs(JSON_OUTPUT_DIR, exist_ok=True)\n","\n","# Embedding model (choose accuracy vs speed)\n","EMBEDDING_MODEL_NAME = \"all-mpnet-base-v2\"   # recommended for accuracy\n","# EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"  # alternative (faster)\n","\n","# Generation model (RAG fusion / answer synthesis)\n","GEN_MODEL_NAME = \"google/flan-t5-base\"  # use GPU for larger models\n","\n","# QA span-extraction model (optional)\n","QA_MODEL_NAME = \"deepset/roberta-base-squad2\"\n","\n","# Tesseract settings\n","pytesseract.pytesseract.tesseract_cmd = \"/usr/bin/tesseract\"  # colab default\n","OCR_LANG = \"eng\"\n","TESSERACT_COMMON_CONFIG = f\"--oem 1 --psm 6 -l {OCR_LANG}\"\n","\n","print(\"Embedding model:\", EMBEDDING_MODEL_NAME)\n","print(\"Generation model:\", GEN_MODEL_NAME)\n","print(\"DB_DIR:\", DB_DIR)\n"],"id":"a5rxZ48MS-ok"},{"cell_type":"code","metadata":{"id":"OggH3Sb3S-ol","executionInfo":{"status":"ok","timestamp":1764728274804,"user_tz":-330,"elapsed":835,"user":{"displayName":"Hariom Ramkrishna","userId":"08131443419838177211"}}},"outputs":[],"execution_count":3,"source":["# OCR-aware PDF extractor and helpers\n","\n","def preprocess_pil_image_for_ocr(pil_img):\n","    img = pil_img.convert(\"L\")\n","    img = ImageOps.autocontrast(img, cutoff=1)\n","    img = img.filter(ImageFilter.MedianFilter(size=3))\n","    return img\n","\n","def extract_text_from_pdf(pdf_path, ocr_if_needed=True, min_text_len_for_layer=50, dpi=300):\n","    all_text = []\n","    with pdfplumber.open(pdf_path) as pdf:\n","        for page_index, page in enumerate(pdf.pages):\n","            try:\n","                text = page.extract_text()\n","            except Exception as e:\n","                print(f\"page.extract_text() error on page {page_index+1}: {e}\")\n","                text = None\n","\n","            if (not text or len(text.strip()) < min_text_len_for_layer) and ocr_if_needed:\n","                print(f\"Page {page_index+1}: Running OCR at {dpi} DPI...\")\n","                try:\n","                    page_image = page.to_image(resolution=dpi).original\n","                except Exception as e:\n","                    print(f\"page.to_image error fallback for page {page_index+1}: {e}\")\n","                    page_image = page.to_image().original\n","                page_image = preprocess_pil_image_for_ocr(page_image)\n","                try:\n","                    text = pytesseract.image_to_string(page_image, config=TESSERACT_COMMON_CONFIG)\n","                except Exception as e:\n","                    print(f\"Tesseract OCR failed on page {page_index+1}: {e}\")\n","                    text = \"\"\n","            if not text:\n","                text = \"\"\n","            all_text.append(f\"\\\\n--- PAGE {page_index+1} ---\\\\n{text}\")\n","    return \"\\\\n\".join(all_text)\n","\n","def extract_text_from_docx(path):\n","    try:\n","        doc = docx.Document(path)\n","        paragraphs = [p.text for p in doc.paragraphs if p.text and p.text.strip()]\n","        return \"\\\\n\".join(paragraphs)\n","    except Exception as e:\n","        print(\"DOCX read error:\", e)\n","        return \"\"\n","\n","def extract_text_from_image(path):\n","    try:\n","        img = Image.open(path)\n","        img = preprocess_pil_image_for_ocr(img)\n","        return pytesseract.image_to_string(img, config=TESSERACT_COMMON_CONFIG)\n","    except Exception as e:\n","        print(\"Image OCR error:\", e)\n","        return \"\"\n"],"id":"OggH3Sb3S-ol"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":129},"id":"jSLKi2K6S-ol","executionInfo":{"status":"ok","timestamp":1764728931694,"user_tz":-330,"elapsed":14133,"user":{"displayName":"Hariom Ramkrishna","userId":"08131443419838177211"}},"outputId":"4e158aa7-f2b6-40a7-d015-4bdf45e77754"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-98a59bd5-7301-48ea-a218-1cb1dbe6b135\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-98a59bd5-7301-48ea-a218-1cb1dbe6b135\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Uniform Residential Loan Application details.docx to Uniform Residential Loan Application details.docx\n","Uploaded: ['Uniform Residential Loan Application details.docx']\n"]}],"execution_count":13,"source":["# Upload files (Colab interactive)\n","from google.colab import files\n","uploaded = files.upload()\n","uploaded_filenames = list(uploaded.keys())\n","print(\"Uploaded:\", uploaded_filenames)"],"id":"jSLKi2K6S-ol"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mkx6T-8MS-ol","executionInfo":{"status":"ok","timestamp":1764728937018,"user_tz":-330,"elapsed":1334,"user":{"displayName":"Hariom Ramkrishna","userId":"08131443419838177211"}},"outputId":"2a0405ba-be6d-4ac0-f761-900f5515bffe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Wrote JSON: /content/doc_jsons/Uniform Residential Loan Application details.json\n","Total chunks prepared: 2\n"]}],"execution_count":14,"source":["# Chunking, process files to JSON and prepare records\n","def chunk_text(text, chunk_size=300, overlap=50):\n","    tokens = text.split()\n","    chunks = []\n","    i = 0\n","    while i < len(tokens):\n","        chunk_tokens = tokens[i:i+chunk_size]\n","        chunks.append(\" \".join(chunk_tokens))\n","        i += chunk_size - overlap\n","    return chunks\n","\n","def process_and_export(files_list):\n","    records = []\n","    for fname in files_list:\n","        path = Path(fname)\n","        ext = path.suffix.lower()\n","        if ext == \".pdf\":\n","            raw = extract_text_from_pdf(str(path))\n","        elif ext in [\".docx\", \".doc\"]:\n","            raw = extract_text_from_docx(str(path))\n","        elif ext in [\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\", \".bmp\"]:\n","            raw = extract_text_from_image(str(path))\n","        else:\n","            print(\"Skipping unsupported:\", fname)\n","            continue\n","\n","        if not raw or len(raw.strip()) == 0:\n","            print(\"No text extracted for:\", fname)\n","            continue\n","\n","        metadata = {\"source_filename\": fname, \"id\": str(uuid.uuid4()), \"n_chars\": len(raw)}\n","        chunks = chunk_text(raw, chunk_size=300, overlap=50)\n","        doc_json = {\"metadata\": metadata, \"full_text\": raw, \"chunks\": []}\n","        for idx, chunk in enumerate(chunks):\n","            chunk_id = f\"{metadata['id']}_chunk_{idx}\"\n","            doc_json[\"chunks\"].append({\"chunk_id\": chunk_id, \"text\": chunk, \"chunk_index\": idx})\n","            records.append({\"id\": chunk_id, \"text\": chunk, \"metadata\": {**metadata, \"chunk_index\": idx}})\n","        outpath = Path(JSON_OUTPUT_DIR) / (path.stem + \".json\")\n","        with open(outpath, \"w\", encoding=\"utf-8\") as f:\n","            json.dump(doc_json, f, ensure_ascii=False, indent=2)\n","        print(\"Wrote JSON:\", outpath)\n","    return records\n","\n","# Run processing on uploaded files\n","records = process_and_export(uploaded_filenames)\n","print(\"Total chunks prepared:\", len(records))"],"id":"Mkx6T-8MS-ol"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A2M2rmoKS-ol","executionInfo":{"status":"ok","timestamp":1764728946748,"user_tz":-330,"elapsed":5774,"user":{"displayName":"Hariom Ramkrishna","userId":"08131443419838177211"}},"outputId":"20682500-bf85-48a1-a930-15a02bb79a08"},"outputs":[{"output_type":"stream","name":"stderr","text":["Embedding: 100%|██████████| 1/1 [00:03<00:00,  3.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Embeddings vectors: 2\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"execution_count":15,"source":["# Load embedding model and create embeddings\n","embed_model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n","texts = [r[\"text\"] for r in records]\n","ids = [r[\"id\"] for r in records]\n","metadatas = [r[\"metadata\"] for r in records]\n","\n","BATCH = 64\n","embeddings = []\n","for i in tqdm(range(0, len(texts), BATCH), desc=\"Embedding\"):\n","    batch_texts = texts[i:i+BATCH]\n","    embs = embed_model.encode(batch_texts, show_progress_bar=False, convert_to_numpy=True)\n","    embeddings.extend(embs)\n","print(\"Embeddings vectors:\", len(embeddings))"],"id":"A2M2rmoKS-ol"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2HurUfuLS-ol","executionInfo":{"status":"ok","timestamp":1764728951559,"user_tz":-330,"elapsed":513,"user":{"displayName":"Hariom Ramkrishna","userId":"08131443419838177211"}},"outputId":"f7c631ff-7082-4ff8-be79-706c38940ad8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Chroma persisted at /content/chroma_db\n"]}],"execution_count":16,"source":["# Create Chroma DB and insert vectors\n","client = chromadb.PersistentClient(path=DB_DIR, settings=Settings())\n","collection_name = \"customer_docs\"\n","try:\n","    collection = client.get_or_create_collection(collection_name)\n","except Exception:\n","    collection = client.create_collection(name=collection_name)\n","\n","# prepare embeddings to lists of floats (Chroma expects python floats)\n","vecs = [e.tolist() if hasattr(e, \"tolist\") else list(map(float, e)) for e in embeddings]\n","\n","collection.add(ids=ids, metadatas=metadatas, documents=texts, embeddings=vecs)\n","print(\"Chroma persisted at\", DB_DIR)"],"id":"2HurUfuLS-ol"},{"cell_type":"code","metadata":{"id":"gjmTROOxS-ol","executionInfo":{"status":"ok","timestamp":1764728955753,"user_tz":-330,"elapsed":506,"user":{"displayName":"Hariom Ramkrishna","userId":"08131443419838177211"}}},"outputs":[],"execution_count":17,"source":["# Retrieval helper\n","def search_chroma(query_text, top_k=3):\n","    q_emb = embed_model.encode([query_text], convert_to_numpy=True)[0].astype(float).tolist()\n","    results = collection.query(query_embeddings=[q_emb], n_results=top_k, include=[\"documents\",\"metadatas\",\"distances\"])\n","    hits = []\n","    for i in range(len(results[\"ids\"][0])):\n","        hits.append({\n","            \"id\": results[\"ids\"][0][i],\n","            \"document\": results[\"documents\"][0][i],\n","            \"metadata\": results[\"metadatas\"][0][i],\n","            \"distance\": results[\"distances\"][0][i]\n","        })\n","    return hits"],"id":"gjmTROOxS-ol"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MN2IRVRIS-om","executionInfo":{"status":"ok","timestamp":1764728960879,"user_tz":-330,"elapsed":1761,"user":{"displayName":"Hariom Ramkrishna","userId":"08131443419838177211"}},"outputId":"5d4ed99a-3aa6-432a-ad44-c9e8df572409"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generation device: cpu\n"]}],"execution_count":18,"source":["# Load generation model (FLAN-T5) for RAG fusion\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Generation device:\", device)\n","\n","gen_tokenizer = AutoTokenizer.from_pretrained(GEN_MODEL_NAME)\n","gen_model = AutoModelForSeq2SeqLM.from_pretrained(GEN_MODEL_NAME).to(device)\n","\n","def tokenize_len(text):\n","    return len(gen_tokenizer.encode(text, truncation=False))\n","def truncate_context_by_tokens(chunks_texts, max_input_tokens, sep=\"\\n\\n---\\n\\n\"):\n","    out = []\n","    tokens = 0\n","    for t in chunks_texts:\n","        t_tokens = len(gen_tokenizer.encode(t + sep, truncation=False))\n","        if tokens + t_tokens > max_input_tokens:\n","            break\n","        out.append(t)\n","        tokens += t_tokens\n","    return sep.join(out)"],"id":"MN2IRVRIS-om"},{"cell_type":"code","metadata":{"id":"Z2ghJkt2S-om","executionInfo":{"status":"ok","timestamp":1764728965586,"user_tz":-330,"elapsed":506,"user":{"displayName":"Hariom Ramkrishna","userId":"08131443419838177211"}}},"outputs":[],"execution_count":19,"source":["# Prompt template and RAG answer function\n","PROMPT_SYSTEM = \"\"\"You are a helpful assistant. Answer the user question using ONLY the CONTEXT provided.\n","If the context does not contain enough information to answer, respond: INSUFFICIENT_CONTEXT.\n","Be concise (max ~120 words). Provide the answer and then list the sources (filename and chunk index).\"\"\"\n","\n","PROMPT_USER_TEMPLATE = \"\"\"\n","CONTEXT:\n","{context}\n","\n","QUESTION:\n","{question}\n","\n","INSTRUCTIONS:\n","1) Give a short direct answer (<120 words).\n","2) After the answer print a \"SOURCES:\" section listing each source as - filename (chunk_index).\n","3) If you can't answer from the context, respond exactly: INSUFFICIENT_CONTEXT\n","\"\"\"\n","\n","def build_prompt(context, question):\n","    return PROMPT_SYSTEM + \"\\n\\n\" + PROMPT_USER_TEMPLATE.format(context=context, question=question)\n","\n","def rag_answer(question, top_k=3, max_context_tokens=1500, max_answer_tokens=180):\n","    # 1. Retrieve\n","    hits = search_chroma(question, top_k=top_k)\n","    if not hits:\n","        return {\"question\": question, \"answer\": \"INSUFFICIENT_CONTEXT\", \"provenance\": [], \"used_context\": \"\"}\n","\n","    # 2. Build entries with provenance\n","    entries = []\n","    provenance = []\n","    for h in hits:\n","        src = h['metadata'].get('source_filename', 'unknown')\n","        idx = h['metadata'].get('chunk_index', -1)\n","        entry_text = f\"[{src} | chunk {idx}]\\n{h['document']}\"\n","        entries.append(entry_text)\n","        provenance.append({\"source\": src, \"chunk_index\": idx, \"distance\": h['distance'], \"id\": h['id']})\n","\n","    # 3. Truncate context to token budget\n","    context = truncate_context_by_tokens(entries, max_context_tokens, sep=\"\\n\\n---\\n\\n\")\n","    prompt = build_prompt(context, question)\n","\n","    # 4. Tokenize & generate\n","    inputs = gen_tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=2048).to(device)\n","    outputs = gen_model.generate(\n","        **inputs,\n","        max_new_tokens=max_answer_tokens,\n","        num_beams=4,\n","        do_sample=False,\n","        early_stopping=True\n","    )\n","    answer = gen_tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n","\n","    if not answer:\n","        answer = \"INSUFFICIENT_CONTEXT\"\n","\n","    return {\"question\": question, \"answer\": answer, \"provenance\": provenance, \"used_context\": context}"],"id":"Z2ghJkt2S-om"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3fuIWaeS-om","executionInfo":{"status":"ok","timestamp":1764728970514,"user_tz":-330,"elapsed":1623,"user":{"displayName":"Hariom Ramkrishna","userId":"08131443419838177211"}},"outputId":"bffba6b5-234e-4d98-c78d-cb92da4172b4"},"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cpu\n"]}],"execution_count":20,"source":["# Optional: QA span extraction for exact fields\n","qa_pipeline = pipeline(\"question-answering\", model=QA_MODEL_NAME, tokenizer=QA_MODEL_NAME, device=0 if torch.cuda.is_available() else -1)\n","\n","def extract_exact_span(question, top_hit):\n","    context = top_hit['document']\n","    res = qa_pipeline(question=question, context=context, top_k=1)\n","    return res"],"id":"d3fuIWaeS-om"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E706mvpYS-om","executionInfo":{"status":"ok","timestamp":1764729254561,"user_tz":-330,"elapsed":12288,"user":{"displayName":"Hariom Ramkrishna","userId":"08131443419838177211"}},"outputId":"d4e68f8a-e87d-41e1-8a6d-b6e18f48e6ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["HIT 1: Customer information.docx chunk 0\n","Page 1: Borrower Information\\nSection 1a. Personal Information \\nName: James A. Smith \\nSocial Security Number: 000-XX-1234 \\nDate of Birth: 06/15/1985 \\nCitizenship: Check Box: U.S. Citizen \\nMarital Status: Check Box: Married \\nDependents: 1 | Ages: 5 \\nCurrent Address: 4509 Maple Drive \\nCity/State/Zip: Austin, TX 78701 \\nHousing: Check Rent ($1,800/month) \\nSection 1b. Employment/Income \\nEmployer Name: Tech Solutions Inc. \\nGross Monthly Income (Base): $8,500 \\nBonus: $500 \\nTotal Income: $\n","distance: 1.2032997608184814\n","-----\n","\n","HIT 2: Uniform Residential Loan Application details.docx chunk 0\n","Uniform Residential Loan Application Summary 3\\nBorrower Name: JACK MERIDITH SPECTOR 4444Lender Loan No/Universal Loan Identifier: US BANK 5Agency Case No.: US-100 6Date of Application Signature: 11/10/2025 7\\nSection 1: Borrower Information 8\\n1a. Personal Information\\nSocial Security Number: 15 52 556 (or Individual Taxpayer Identification Number) 9999\\nDate of Birth (mm/dd/yyyy): 02/02/2000 10\\nCitizenship: U.S. Citizen 11\\nType of Credit: Individual credit 12\\nOther Borrowers: NA 13\\nMarital\n","distance: 1.372542381286621\n","-----\n","\n","HIT 3: Uniform Residential Loan Application details.docx chunk 1\n","real estate42.\\nSections 3a, 3b, and 3c do not apply434343434343434343.\\nSection 4: Loan and Property Information 44\\n4a. Loan and Property Information\\nLoan Amount: $ 200000.00 45\\nLoan Purpose: Purchase 46\\nProperty Value: $ 500000.00 47\\nProperty Address: BAKERS STREET Unit # 5, NEWYORK, NC, ZIP 12563, USA 48484848\\nNumber of Units: 55 49\\nOccupancy: Investment Property 50\\nMixed-Use Property (Business Space): NO 51\\nManufactured Home: NO 52\\n4b. Other New Mortgage Loans\\nDoes not apply53.\\n4\n","distance: 1.4705379009246826\n","-----\n","\n","ANSWER:\n"," [Customer information.docx | chunk 0]\n","\n","PROVENANCE:\n"," [{'source': 'Customer information.docx', 'chunk_index': 0, 'distance': 1.2032997608184814, 'id': '90b48738-aca5-42be-997f-c89476ea3bd4_chunk_0'}, {'source': 'Uniform Residential Loan Application details.docx', 'chunk_index': 0, 'distance': 1.372542381286621, 'id': '62852365-0f32-4766-abdb-d561360b3e13_chunk_0'}, {'source': 'Uniform Residential Loan Application details.docx', 'chunk_index': 1, 'distance': 1.4705379009246826, 'id': '62852365-0f32-4766-abdb-d561360b3e13_chunk_1'}]\n","\n","Exact span extracted by QA model: {'score': 3.269751914558583e-06, 'start': 462, 'end': 468, 'answer': '$8,500'}\n"]}],"execution_count":25,"source":["# Examples / Usage\n","\n","# Retrieval-only example:\n","q = \"list of all the customers with monthly income greater than 5000 dollars?\"\n","hits = search_chroma(q, top_k=3)\n","for i,h in enumerate(hits,1):\n","    print(f\"HIT {i}: {h['metadata']['source_filename']} chunk {h['metadata']['chunk_index']}\")\n","    print(h['document'][:500].replace(\"\\n\",\" \"))\n","    print(\"distance:\", h['distance'])\n","    print(\"-----\\n\")\n","\n","# RAG: generate concise, grounded answer\n","out = rag_answer(q, top_k=3)\n","print(\"ANSWER:\\n\", out[\"answer\"])\n","print(\"\\nPROVENANCE:\\n\", out[\"provenance\"])\n","\n","# Optional: exact span from top hit\n","if hits:\n","    span = extract_exact_span(q, hits[0])\n","    print(\"\\nExact span extracted by QA model:\", span)"],"id":"E706mvpYS-om"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FwiwJIc_S-om","executionInfo":{"status":"ok","timestamp":1764700402264,"user_tz":-330,"elapsed":1094,"user":{"displayName":"Hariom Ramkrishna","userId":"08131443419838177211"}},"outputId":"ef064e64-d328-462c-8adb-72590fd38cb4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Zipped at /content/chroma_db.zip and /content/doc_jsons.zip\n"]}],"execution_count":null,"source":["# Save DB and JSONs for download (optional)\n","!zip -r -q /content/chroma_db.zip /content/chroma_db\n","!zip -r -q /content/doc_jsons.zip /content/doc_jsons\n","print(\"Zipped at /content/chroma_db.zip and /content/doc_jsons.zip\")"],"id":"FwiwJIc_S-om"}]}